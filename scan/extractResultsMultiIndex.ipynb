{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SLHA, SModelS output and store the data in a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T12:07:45.675249Z",
     "start_time": "2024-01-26T12:07:45.404407Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "import pandas as pd\n",
    "import glob,os\n",
    "import numpy as np\n",
    "from pandas import json_normalize\n",
    "from importlib import util\n",
    "import pyslha\n",
    "import sys\n",
    "sys.path.append(os.path.expanduser('~/smodels'))\n",
    "from smodels.share.models.SMparticles import SMList\n",
    "from smodels.base.model import Model\n",
    "from smodels.tools.particlesLoader import getParticlesFromSLHA\n",
    "\n",
    "pd.options.mode.chained_assignment = None #Disable copy warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T12:07:45.852904Z",
     "start_time": "2024-01-26T12:07:45.676838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gha, gha~, ghz, ghz~, ghwp, ghwp~, ghwm, ghwm~, ghg, ghg~, zp, ghzp, ghzp~, sd, chi]\n"
     ]
    }
   ],
   "source": [
    "BSMlist = getParticlesFromSLHA('./2mdm_example.slha')\n",
    "model = Model(BSMparticles=BSMlist, SMparticles=SMList)\n",
    "print(BSMlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T12:07:46.127272Z",
     "start_time": "2024-01-26T12:07:45.855555Z"
    }
   },
   "outputs": [],
   "source": [
    "slhaFolder = '../data/slha_files'\n",
    "smodelsFolder = '../data/smodels_results'\n",
    "parametersSmodels = './smodels_parameters_2mdm.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T00:53:06.818129Z",
     "start_time": "2024-01-26T00:53:06.256767Z"
    }
   },
   "outputs": [],
   "source": [
    "#Convert Experimental Results list to a dictionary\n",
    "data = []\n",
    "removeFromDict = ['topologies outside the grid',\"missing topologies\",\n",
    "                  \"missing topologies with displaced decays\", \n",
    "                  'missing topologies with prompt decays',\n",
    "                 \"Asymmetric Branches\",\"Outside Grid\",\n",
    "                 \"Missed Topologies\",\"Long Cascades\",\n",
    "                 \"OutputStatus\",\n",
    "                #  \"Total xsec for missing topologies (fb)\", \n",
    "                #  \"Total xsec for missing topologies with displaced decays (fb)\",\n",
    "                #  \"Total xsec for missing topologies with prompt decays (fb)\",\n",
    "                #  \"Total xsec for topologies outside the grid (fb)\"\n",
    "                ]\n",
    "\n",
    "nfiles = 0\n",
    "exptResData = []\n",
    "for f in glob.glob(smodelsFolder+'/*.py'):\n",
    "    # nfiles += 1\n",
    "    # if nfiles > 5:\n",
    "        # break\n",
    "    spec = util.spec_from_file_location(\"smodelsOutput\", f)\n",
    "    smodelsOutput = util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(smodelsOutput)\n",
    "    smodelsDict = smodelsOutput.smodelsOutput\n",
    "    for rmKey in removeFromDict:\n",
    "        if rmKey in smodelsDict:\n",
    "            smodelsDict.pop(rmKey)\n",
    "        slhaFile = f.replace('.py','')\n",
    "    smodelsDict['filename'] = os.path.basename(slhaFile)\n",
    "    if 'CombinedRes' in smodelsDict:\n",
    "        smodelsDict['ExptRes'] += smodelsDict.pop('CombinedRes')\n",
    "    if 'ExptRes' in smodelsDict:\n",
    "        expList = sorted(smodelsDict.pop('ExptRes'), \n",
    "                            key=lambda pt: (pt['r'] is not None,pt['r']),\n",
    "                            reverse=True)\n",
    "        for iexp,exp in enumerate(expList):\n",
    "            # newDict = {k : v for k,v in smodelsDict.items()}\n",
    "            newDict = {'filename' : smodelsDict['filename']}\n",
    "            newDict['ExptRes'] = iexp\n",
    "            newDict.update({k : v for k,v in exp.items()})\n",
    "            exptResData.append(newDict)\n",
    "    else:\n",
    "        newDict = {'filename' : smodelsDict['filename'], 'ExptRes' : None}\n",
    "        exptResData.append(newDict)\n",
    "    data.append(smodelsDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points: 21000\n"
     ]
    }
   ],
   "source": [
    "dataDF = pd.DataFrame(data)\n",
    "dataDF.set_index('filename',inplace=True)\n",
    "expDF = pd.DataFrame(exptResData)\n",
    "expDF.set_index(['filename','ExptRes'],inplace=True)\n",
    "smodelsDF = expDF.join(dataDF, how='outer')\n",
    "# smodelsDF = expDF.join(dataDF, how='inner')\n",
    "print(f'Number of data points: {len(smodelsDF.groupby(level=0))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T00:53:11.235055Z",
     "start_time": "2024-01-26T00:53:07.386195Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get SLHA data:\n",
    "slhaData = []\n",
    "for f in smodelsDF.index.get_level_values('filename').unique():\n",
    "    slhaFile = os.path.join(slhaFolder,f)\n",
    "    slha = pyslha.readSLHAFile(slhaFile)\n",
    "    massDict = dict([[str(key),abs(val)] for key,val in slha.blocks['MASS'].items() if key >= 52])\n",
    "    extparDict = dict([[str(key),val] for key,val in slha.blocks['NPINPUTS'].items()])\n",
    "    \n",
    "    widthDict = dict([[str(key),val.totalwidth] for key,val in slha.decays.items() if key >= 52])\n",
    "    BRsDict = {}\n",
    "    for pdg,val in slha.decays.items():\n",
    "        initialState = model.getParticlesWith(pdg=pdg)[0].label            \n",
    "        BRsDict[initialState] = {}\n",
    "        for dec in val.decays:\n",
    "            if dec.br < 1e-7: continue            \n",
    "            finalState = ','.join([model.getParticlesWith(pdg=pid)[0].label for pid in sorted(dec.ids)])\n",
    "            BRsDict[initialState][finalState] = dec.br\n",
    "    xsec8TeV = dict([ [str(proc.pidsfinal).replace('[','').replace(']','').replace(',','_').replace(' ',''),\n",
    "                   max([x.value for x in proc.get_xsecs(sqrts=8000)])*1000] \n",
    "                 for proc in slha.xsections.values()  if proc.get_xsecs(sqrts=8000)])\n",
    "    xsec13TeV = dict([ [str(proc.pidsfinal).replace('[','').replace(']','').replace(',','_').replace(' ',''),\n",
    "                   max([x.value for x in proc.get_xsecs(sqrts=13000)])*1000] \n",
    "                 for proc in slha.xsections.values()  if proc.get_xsecs(sqrts=13000)])    \n",
    "    slhaDict = {'filename' : f, 'mass' : massDict, 'width' : widthDict, 'extpar' : extparDict, \n",
    "                'xsec8TeV(fb)' : xsec8TeV, 'xsec13TeV(fb)' : xsec13TeV, 'BRs' : BRsDict}\n",
    "    slhaData.append(slhaDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "slhaDF = json_normalize(slhaData)\n",
    "slhaDF.set_index(['filename'],inplace=True)\n",
    "#Add total cross-sections:\n",
    "xsecs13 = [x for x in list(slhaDF) if 'xsec13TeV' in x]\n",
    "xsecs8 = [x for x in list(slhaDF) if 'xsec8TeV' in x]\n",
    "slhaDF['totalxsec13TeV(fb)'] = slhaDF[xsecs13].sum(axis=1)\n",
    "slhaDF['totalxsec8TeV(fb)'] = slhaDF[xsecs8].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T00:53:11.567012Z",
     "start_time": "2024-01-26T00:53:11.273225Z"
    }
   },
   "outputs": [],
   "source": [
    "#Merge with SModelS DataFrame\n",
    "allDF = smodelsDF.join(slhaDF, how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-26T00:53:11.794329Z",
     "start_time": "2024-01-26T00:53:11.570788Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of data points: 21000\n"
     ]
    }
   ],
   "source": [
    "print(f'Final number of data points: {len(allDF.groupby(level=0))}')\n",
    "#print(dataDF2.columns.values.tolist()) #Print all columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save DataFrame to pickle file:\n",
    "allDF.to_pickle('../data/smodels_results_v3.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
