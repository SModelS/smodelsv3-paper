{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read SLHA, SModelS output and store the data in a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2881/1716768401.py:5: DeprecationWarning: the imp module is deprecated in favour of importlib and slated for removal in Python 3.12; see the module's documentation for alternative uses\n",
      "  import glob,imp,os,sys\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob,imp,os,sys\n",
    "from pandas import json_normalize\n",
    "import pyslha\n",
    "sys.path.append('/home/yoxara/smodels')\n",
    "from smodels.share.models.mssm import BSMList\n",
    "from smodels.share.models.SMparticles import SMList\n",
    "from smodels.base.model import Model\n",
    "from smodels.particlesLoader import getParticlesFromSLHA\n",
    "\n",
    "pd.options.mode.chained_assignment = None #Disable copy warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gha, gha~, ghz, ghz~, ghwp, ghwp~, ghwm, ghwm~, ghg, ghg~, zp, ghzp, ghzp~, sd, chi]\n"
     ]
    }
   ],
   "source": [
    "BSMlist = getParticlesFromSLHA('/home/yoxara/2MDM/2mdm_slha_files_all/run_01_zp_3612_dm_1412_gqv_06.slha')\n",
    "model = Model(BSMparticles=BSMlist, SMparticles=SMList)\n",
    "print(BSMlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "slhaFolder = '/home/yoxara/2MDM/2mdm_slha_files_all'\n",
    "smodelsFolder = '/home/yoxara/2MDM/notebooks/SmodelS/2mdm_all_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO in databaseObj.loadBinaryFile() in 526: loading binary db file /home/yoxara/smodels/smodels-database/db3.pcl format version 214\n",
      "INFO in databaseObj.loadBinaryFile() in 533: Loaded database from /home/yoxara/smodels/smodels-database/db3.pcl in 13.0 secs.\n",
      "INFO in modelTester.loadDatabaseResults() in 498: Including non-validated results\n",
      "INFO in modelTester.testPoints() in 358: Running SModelS for 1870 files with a single process. Messages will be redirected to smodels.log\n"
     ]
    }
   ],
   "source": [
    "!runSModelS.py -p /home/yoxara/2MDM/notebooks/SmodelS/parameters_2mdm.ini -f /home/yoxara/2MDM/2mdm_slha_files_all -o /home/yoxara/2MDM/notebooks/SmodelS/2mdm_all_results/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Experimental Results list to a dictionary\n",
    "data = []\n",
    "removeFromDict = ['topologies outside the grid',\"missing topologies\",\n",
    "                  \"missing topologies with displaced decays\", 'missing topologies with prompt decays',\n",
    "                 \"Asymmetric Branches\",\"Outside Grid\",\"Missed Topologies\",\"Long Cascades\"]\n",
    "for f in glob.glob(smodelsFolder+'/*.py'):\n",
    "    with open(f,'r') as ff:\n",
    "        dataF = ff.read()\n",
    "    dataF = dataF.replace('inf','-1')\n",
    "    with open(f.replace('.py','_fix.py'),'w') as ff:\n",
    "        ff.write(dataF)\n",
    "    f = f.replace('.py','_fix.py')\n",
    "    smodelsDict = imp.load_source(f.replace('.py',''),f).smodelsOutput\n",
    "    for rmKey in removeFromDict:\n",
    "        if rmKey in smodelsDict:\n",
    "            smodelsDict.pop(rmKey)\n",
    "    if 'ExptRes' in smodelsDict:\n",
    "        for res in smodelsDict['ExptRes']:\n",
    "            if 'TxNames weights (fb)' in res:\n",
    "                res.pop('TxNames weights (fb)')  \n",
    "        expList = sorted(smodelsDict['ExptRes'], key=lambda pt: pt['r'],reverse=True)\n",
    "        expDict = dict([['result%i'%i,val] for i,val in enumerate(expList)])\n",
    "        smodelsDict['ExptRes'] = expDict\n",
    "    slhaFile = smodelsDict['OutputStatus']['input file']\n",
    "    dataDict = {'filename' : os.path.basename(slhaFile)}\n",
    "    dataDict.update(smodelsDict)\n",
    "    data.append(dataDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3740\n"
     ]
    }
   ],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data to flat DataFrame:\n",
    "smodelsDF = json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get SLHA data:\n",
    "slhaData = []\n",
    "for f in smodelsDF['filename']:\n",
    "    slhaFile = os.path.join(slhaFolder,f)\n",
    "    slha = pyslha.readSLHAFile(slhaFile)\n",
    "    massDict = dict([[str(key),abs(val)] for key,val in slha.blocks['MASS'].items() if key >= 9000006])\n",
    "    extparDict = dict([[str(key),val] for key,val in slha.blocks['FRBLOCK'].items()])\n",
    "    extparDict.update(dict([[str(key),val] for key,val in slha.blocks['BLINPUTS'].items()]))\n",
    "    widthDict = dict([[str(key),val.totalwidth] for key,val in slha.decays.items() if key >= 9000006])\n",
    "    BRsDict = {}\n",
    "    for pdg,val in slha.decays.items():\n",
    "#         if not abs(pdg) in [1000024,1000023]:\n",
    "#             continue\n",
    "        initialState = model.getParticlesWith(pdg=pdg)[0].label            \n",
    "        BRsDict[initialState] = {}\n",
    "        for dec in val.decays:\n",
    "            if dec.br < 0.01: continue            \n",
    "            finalState = ','.join([model.getParticlesWith(pdg=pid)[0].label for pid in sorted(dec.ids)])\n",
    "            BRsDict[initialState][finalState] = dec.br\n",
    "    xsec8TeV = dict([ [str(proc.pidsfinal).replace('[','').replace(']','').replace(',','_').replace(' ',''),\n",
    "                   max([x.value for x in proc.get_xsecs(sqrts=8000)])*1000] \n",
    "                 for proc in slha.xsections.values()  if proc.get_xsecs(sqrts=8000)])\n",
    "    xsec13TeV = dict([ [str(proc.pidsfinal).replace('[','').replace(']','').replace(',','_').replace(' ',''),\n",
    "                   max([x.value for x in proc.get_xsecs(sqrts=13000)])*1000] \n",
    "                 for proc in slha.xsections.values()  if proc.get_xsecs(sqrts=13000)])    \n",
    "    slhaDict = {'filename' : f, 'mass' : massDict, 'width' : widthDict, 'extpar' : extparDict, \n",
    "                'xsec8TeV(fb)' : xsec8TeV, 'xsec13TeV(fb)' : xsec13TeV, 'BRs' : BRsDict}\n",
    "    slhaData.append(slhaDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to DataFrame\n",
    "slhaDF = json_normalize(slhaData)\n",
    "#Add total cross-sections:\n",
    "xsecs13 = [x for x in list(slhaDF) if 'xsec13TeV' in x]\n",
    "xsecs8 = [x for x in list(slhaDF) if 'xsec8TeV' in x]\n",
    "slhaDF['totalxsec13TeV(fb)'] = slhaDF[xsecs13].sum(axis=1)\n",
    "slhaDF['totalxsec8TeV(fb)'] = slhaDF[xsecs8].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with SModelS DataFrame\n",
    "dataDF = slhaDF.merge(smodelsDF,how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of data points: 7480\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Final number of data points:',dataDF.shape[0])\n",
    "#print(dataDF2.columns.values.tolist()) #Print all columns names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save DataFrame to pickle file:\n",
    "dataDF.to_pickle('/home/yoxara/2MDM/notebooks/SmodelS/2MDM_scanResults_all.pcl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7480\n"
     ]
    }
   ],
   "source": [
    "print(len(dataDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database version: 3.0.0-beta\n",
      "-----------------------------\n",
      "206 experimental results: 93 CMS, 113 ATLAS, 77 @ 8 TeV, 129 @ 13 TeV\n",
      "1322 datasets, 7269 txnames.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from smodels.experiment.databaseObj import Database\n",
    "path = \"/home/yoxara/smodels/smodels-database\" # Path to database\n",
    "db = Database(path) # Load database and model\n",
    "#analysis_list = ['all']%['CMS-PAS-EXO-20-008', 'ATLAS-EXOT-2018-48', 'ATLAS-EXOT-2019-03', 'CMS-EXO-19-012','CMS-EXO-20-004-eff']\n",
    "#db.selectExpResults(analysisIDs=analysis_list, txnames='all')#, useNonValidated=True)#, dataTypes='upperLimit'\n",
    "print(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database version: 3.0.0-beta\n",
      "-----------------------------\n",
      "1 experimental results: 0 CMS, 1 ATLAS, 0 @ 8 TeV, 1 @ 13 TeV\n",
      "1 datasets, 2 txnames.\n",
      " [<smodels.experiment.expResultObj.ExpResult object at 0x7f7093572080>]\n",
      "Database version: 3.0.0-beta\n",
      "-----------------------------\n",
      "1 experimental results: 1 CMS, 0 ATLAS, 0 @ 8 TeV, 1 @ 13 TeV\n",
      "1 datasets, 1 txnames.\n",
      " [<smodels.experiment.expResultObj.ExpResult object at 0x7f7093572050>]\n",
      "Database version: 3.0.0-beta\n",
      "-----------------------------\n",
      "1 experimental results: 0 CMS, 1 ATLAS, 0 @ 8 TeV, 1 @ 13 TeV\n",
      "1 datasets, 1 txnames.\n",
      " [<smodels.experiment.expResultObj.ExpResult object at 0x7f7093571f30>]\n",
      "Database version: 3.0.0-beta\n",
      "-----------------------------\n",
      "1 experimental results: 0 CMS, 1 ATLAS, 0 @ 8 TeV, 1 @ 13 TeV\n",
      "1 datasets, 2 txnames.\n",
      " [<smodels.experiment.expResultObj.ExpResult object at 0x7f7093572050>]\n",
      "Database version: 3.0.0-beta\n",
      "-----------------------------\n",
      "2 experimental results: 2 CMS, 0 ATLAS, 0 @ 8 TeV, 2 @ 13 TeV\n",
      "23 datasets, 46 txnames.\n",
      " [<smodels.experiment.expResultObj.ExpResult object at 0x7f7093573fa0>, <smodels.experiment.expResultObj.ExpResult object at 0x7f7093571ae0>]\n"
     ]
    }
   ],
   "source": [
    "print(db, db.getExpResults('ATLAS-EXOT-2019-03'))\n",
    "print(db, db.getExpResults('CMS-PAS-EXO-20-008'))\n",
    "print(db, db.getExpResults('ATLAS-EXOT-2018-48'))\n",
    "print(db, db.getExpResults('ATLAS-EXOT-2019-03'))\n",
    "print(db, db.getExpResults('CMS-SUS-20-004'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
